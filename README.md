# Web Scraping Server - Italy & Romania Software Companies

A production-ready Node.js web scraping server designed to extract comprehensive software company data from Italy and Romania, targeting both international platforms (LinkedIn, Crunchbase) and country-specific business registries.

## ğŸ¯ Features

- **Multi-Source Scraping**: 10+ data sources per country
- **Crunchbase Integration**: Startup and funding data via API
- **Country-Specific Data**: Normalized for Italian and Romanian business standards
- **Automatic Deduplication**: Smart duplicate detection and merging
- **RESTful API**: Comprehensive endpoints for data access
- **Queue Processing**: Background job processing with Bull
- **Real-time Progress**: Job status tracking and monitoring
- **Data Export**: CSV/JSON export capabilities
- **Proxy Support**: Country-specific proxy configuration
- **GDPR Compliant**: Secure data handling

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Express API Server          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚     Middleware Layer         â”‚  â”‚
â”‚  â”‚  Auth | RateLimit | Validate â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚     Controllers Layer        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                 â”‚
         â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Queue System  â”‚  â”‚   Supabase  â”‚
â”‚  (Bull+Redis)  â”‚  â”‚  PostgreSQL â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Scraper Workers        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Italy Scrapers  â”‚    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚  â”‚ Romania Scrapers â”‚    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚  â”‚ LinkedIn Scraper â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Data Sources

### ğŸ‡®ğŸ‡¹ Italy Sources
- **Registro Imprese** - Official Italian Business Registry
- **Pagine Gialle** - Italian Yellow Pages
- **InfoCamere** - Chamber of Commerce database
- **Crunchbase** - Startup and funding data

### ğŸ‡·ğŸ‡´ Romania Sources
- **ONRC** - Romanian Trade Registry
- **Lista Firme** - Romanian business directory
- **ANIS** - Romanian IT Association
- **Crunchbase** - Startup and funding data

## ğŸš€ Quick Start

### Prerequisites
- Node.js 18+ (LTS)
- Supabase account
- Redis instance
- 16GB RAM minimum
- Multi-core CPU (4+ cores recommended)

### Installation

1. **Clone the repository**
```bash
git clone <repository-url>
cd scraping-server
```

2. **Install dependencies**
```bash
npm install
```

3. **Setup environment variables**
```bash
cp env.example .env
# Edit .env with your credentials
```

4. **Initialize database**
```bash
npm run db:migrate
npm run db:seed
```

5. **Start the server**
```bash
npm run dev
```

6. **Start worker (in separate terminal)**
```bash
npm run worker
```

## ğŸ”§ Configuration

### Environment Variables

```bash
# Supabase Configuration
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_ANON_KEY=your-anon-key
SUPABASE_SERVICE_KEY=your-service-key

# Redis Configuration
REDIS_HOST=localhost
REDIS_PORT=6379

# LinkedIn Configuration (Disabled for security reasons)
# LINKEDIN_EMAIL=your-linkedin-email
# LINKEDIN_PASSWORD=your-linkedin-password

# API Security
API_KEY=your-secret-api-key
```

## ğŸ“¡ API Endpoints

### Base URL: `http://localhost:3000/api/v1`

### Authentication
All endpoints require API key in header:
```
X-API-Key: your-secret-api-key
```

### Scraping Endpoints

#### **POST /scrape/italy**
Start Italy scraping job
```json
{
  "sources": ["pagine_gialle", "registro_imprese"],
  "cities": ["Milano", "Roma"],
  "async": true
}
```

#### **POST /scrape/romania**
Start Romania scraping job
```json
{
  "sources": ["listafirme", "onrc"],
  "cities": ["BucureÈ™ti", "Cluj-Napoca"],
  "async": true
}
```


### Company Endpoints

#### **GET /companies**
List companies with filters
```
Query params:
- country: IT | RO
- city: string
- industry: string
- min_employees: number
- max_employees: number
- has_website: boolean
- page: number
- limit: number
```

#### **GET /companies/:id**
Get single company details

#### **GET /companies/export/csv**
Export companies to CSV

### Job Management

#### **GET /scrape/jobs**
List all scraping jobs

#### **GET /scrape/jobs/:jobId**
Get job status and progress

#### **DELETE /scrape/jobs/:jobId**
Cancel a job

## ğŸ§ª Testing

### Test Italy Scrapers
```bash
npm run scrape:italy
npm run test:proxies
```

### Test Romania Scrapers
```bash
npm run scrape:romania
```

### Run Unit Tests
```bash
npm test
```

### Run Integration Tests
```bash
npm run test:integration
```

## ğŸ“ˆ Expected Results

After 24 hours of operation, you should have:

### Italy Data
- âœ… 1,500-2,500 Italian software companies
- âœ… 3+ data sources operational
- âœ… 70%+ data completeness
- âœ… Major cities covered (Milano, Roma, Torino, Bologna)

### Romania Data
- âœ… 1,500-2,500 Romanian software companies
- âœ… 3+ data sources operational
- âœ… 70%+ data completeness
- âœ… Major cities covered (BucureÈ™ti, Cluj-Napoca, TimiÈ™oara, IaÈ™i)

### Crunchbase Enhancement
- âœ… 200-500 companies from both countries
- âœ… Enhanced data (funding information, startup details)
- âœ… 80%+ data accuracy

## ğŸ”’ Security & Compliance

- **GDPR Compliant**: Only public business data
- **Rate Limiting**: Respects source rate limits
- **API Authentication**: Secure API key authentication
- **Data Encryption**: HTTPS only in production
- **Input Validation**: Comprehensive request validation

## ğŸ“Š Monitoring

### Key Metrics
- Jobs completed/hour
- Average scraping time per source
- Success rate by source
- Data quality scores
- API response times

### Health Check
```bash
curl http://localhost:3000/health
```

## ğŸ› ï¸ Development

### Project Structure
```
scraping-server/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/           # Configuration files
â”‚   â”œâ”€â”€ scrapers/         # Scraper implementations
â”‚   â”œâ”€â”€ services/         # Business logic services
â”‚   â”œâ”€â”€ controllers/      # API controllers
â”‚   â”œâ”€â”€ middleware/       # Express middleware
â”‚   â”œâ”€â”€ routes/          # API routes
â”‚   â””â”€â”€ utils/           # Utility functions
â”œâ”€â”€ supabase/            # Database migrations
â”œâ”€â”€ scripts/             # Setup and testing scripts
â””â”€â”€ tests/               # Test files
```

### Adding New Scrapers

1. Create scraper class extending `BaseScraper`
2. Implement `scrape()` and `parse()` methods
3. Register in `ScraperFactory`
4. Add to configuration

### Adding New Data Sources

1. Create scraper for the source
2. Add to `data_sources` table
3. Update configuration files
4. Test with real data

## ğŸš€ Deployment

### Docker Deployment
```bash
docker-compose up -d
```

### Production Checklist
- [ ] Environment variables configured
- [ ] Database migrations run
- [ ] Redis connection tested
- [ ] API key generated and secured
- [ ] CORS origins configured
- [ ] Rate limits configured
- [ ] SSL certificate installed
- [ ] Monitoring setup

## ğŸ“ Support

### Getting Help
- Check documentation first
- Review troubleshooting guide
- Check GitHub issues
- Contact development team

### Reporting Bugs
```markdown
**Bug Report Template**
- Title: Brief description
- Environment: Development/Production
- Steps to reproduce
- Expected behavior
- Actual behavior
- Error messages/logs
```

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ‰ Acknowledgments

- Supabase for the database platform
- Puppeteer for browser automation
- Cheerio for HTML parsing
- Bull for job queue management

---

**Ready to start scraping? Let's build the most comprehensive database of Italian and Romanian software companies! ğŸš€**
